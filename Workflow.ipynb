{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow & Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üè† Import the house price data set. We will keep only numerical features for the sake of simplicity\n",
    "\n",
    "üéØ Your goal will be to fit the best KNN Regressor. In particular, how many \"neighbors\" (<font color=blue>K</font> in <font color=blue>K</font>NN) should you consider to get the best predictions for your house prices ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>...</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>196.0</td>\n",
       "      <td>706</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>298</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>162.0</td>\n",
       "      <td>486</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>216</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>350.0</td>\n",
       "      <td>655</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>192</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>60</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7917</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1999</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>175000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>20</td>\n",
       "      <td>85.0</td>\n",
       "      <td>13175</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1978</td>\n",
       "      <td>1988</td>\n",
       "      <td>119.0</td>\n",
       "      <td>790</td>\n",
       "      <td>163</td>\n",
       "      <td>...</td>\n",
       "      <td>349</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>70</td>\n",
       "      <td>66.0</td>\n",
       "      <td>9042</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>1941</td>\n",
       "      <td>2006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>275</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2500</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>266500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>20</td>\n",
       "      <td>68.0</td>\n",
       "      <td>9717</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1950</td>\n",
       "      <td>1996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49</td>\n",
       "      <td>1029</td>\n",
       "      <td>...</td>\n",
       "      <td>366</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>142125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1460</th>\n",
       "      <td>20</td>\n",
       "      <td>75.0</td>\n",
       "      <td>9937</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1965</td>\n",
       "      <td>1965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>830</td>\n",
       "      <td>290</td>\n",
       "      <td>...</td>\n",
       "      <td>736</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "      <td>147500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1121 rows √ó 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "Id                                                                            \n",
       "1             60         65.0     8450            7            5       2003   \n",
       "2             20         80.0     9600            6            8       1976   \n",
       "3             60         68.0    11250            7            5       2001   \n",
       "4             70         60.0     9550            7            5       1915   \n",
       "5             60         84.0    14260            8            5       2000   \n",
       "...          ...          ...      ...          ...          ...        ...   \n",
       "1456          60         62.0     7917            6            5       1999   \n",
       "1457          20         85.0    13175            6            6       1978   \n",
       "1458          70         66.0     9042            7            9       1941   \n",
       "1459          20         68.0     9717            5            6       1950   \n",
       "1460          20         75.0     9937            5            6       1965   \n",
       "\n",
       "      YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  ...  WoodDeckSF  \\\n",
       "Id                                                      ...               \n",
       "1             2003       196.0         706           0  ...           0   \n",
       "2             1976         0.0         978           0  ...         298   \n",
       "3             2002       162.0         486           0  ...           0   \n",
       "4             1970         0.0         216           0  ...           0   \n",
       "5             2000       350.0         655           0  ...         192   \n",
       "...            ...         ...         ...         ...  ...         ...   \n",
       "1456          2000         0.0           0           0  ...           0   \n",
       "1457          1988       119.0         790         163  ...         349   \n",
       "1458          2006         0.0         275           0  ...           0   \n",
       "1459          1996         0.0          49        1029  ...         366   \n",
       "1460          1965         0.0         830         290  ...         736   \n",
       "\n",
       "      OpenPorchSF  EnclosedPorch  3SsnPorch  ScreenPorch  PoolArea  MiscVal  \\\n",
       "Id                                                                            \n",
       "1              61              0          0            0         0        0   \n",
       "2               0              0          0            0         0        0   \n",
       "3              42              0          0            0         0        0   \n",
       "4              35            272          0            0         0        0   \n",
       "5              84              0          0            0         0        0   \n",
       "...           ...            ...        ...          ...       ...      ...   \n",
       "1456           40              0          0            0         0        0   \n",
       "1457            0              0          0            0         0        0   \n",
       "1458           60              0          0            0         0     2500   \n",
       "1459            0            112          0            0         0        0   \n",
       "1460           68              0          0            0         0        0   \n",
       "\n",
       "      MoSold  YrSold  SalePrice  \n",
       "Id                               \n",
       "1          2    2008     208500  \n",
       "2          5    2007     181500  \n",
       "3          9    2008     223500  \n",
       "4          2    2006     140000  \n",
       "5         12    2008     250000  \n",
       "...      ...     ...        ...  \n",
       "1456       8    2007     175000  \n",
       "1457       2    2010     210000  \n",
       "1458       5    2010     266500  \n",
       "1459       4    2010     142125  \n",
       "1460       6    2008     147500  \n",
       "\n",
       "[1121 rows x 37 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load raw data\n",
    "data = pd.read_csv('https://wagon-public-datasets.s3.amazonaws.com/houses_train_raw.csv', index_col=\"Id\")\n",
    "\n",
    "# Only keep numerical columns and raws without NaN\n",
    "data = data.select_dtypes(include=np.number).dropna()\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=['SalePrice'])\n",
    "y = data['SalePrice']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Train/Test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question (Holdout)**‚ùì\n",
    "\n",
    "üëá Split the dataset to create your `X_train` `X_test` and `y_train` `y_test`. Use:\n",
    "- `test_size=0.3`\n",
    "- `random_state=0` to compare your results with your buddy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚öñÔ∏è Scaling is always crucially important for the KNN algorithm..\n",
    "\n",
    "‚ùì **Question (Scaling)** ‚ùì \n",
    "\n",
    "* Scale your train set and test set.\n",
    "* Here, let's simply apply the `StandardScaler` and not waste time choosing one scaler per feature. Indeed, the goals of this exercise are to:\n",
    "    * review KNN\n",
    "    * understand GridSearchCV\n",
    "    * understand RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Baseline KNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question (A baseline for our KNN)** ‚ùì\n",
    "\n",
    "Cross-validate (*cv = 5*) a simple KNN regressor taking into account only _the closest neighbor_, and compute the average score over the 5 folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5709591350962517"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "model = KNeighborsRegressor(n_neighbors=1)\n",
    "check = cross_validate(model, X_train, y_train, cv=10)\n",
    "check['test_score'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. A first GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question (GridSearch v1)**‚ùì\n",
    "\n",
    "Let's use SKLearn `GridSearchCV` to find the best KNN hyperparameter `n_neighbors`.\n",
    "- Start a coarse-grain approach, with `n_neighbors` = [1,5,10,20,50]\n",
    "- 5-fold cross-validate each parameter\n",
    "- Make sure to maximize your performance time using `n_jobs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Instantiate model\n",
    "\n",
    "model = KNeighborsRegressor()\n",
    "# Hyperparameter Grid\n",
    "grid = {'n_neighbors': [1,5,10,20,50]}\n",
    "\n",
    "# Instantiate Grid Search\n",
    "g_search = GridSearchCV(model,grid,cv = 5, n_jobs=-1)\n",
    "\n",
    "# Fit data to Grid Search\n",
    "g_search.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question (best parameters)** ‚ùì\n",
    "\n",
    "According to the GridSearch, what is the optimal K value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "k= g_search.best_params_\n",
    "best_k= 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question (scoring)** ‚ùì What is the best score the optimal K value produced?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = g_search.best_score_\n",
    "best_score =round(score,2)\n",
    "best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. A second GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question (GridSearch V2)** ‚ùì\n",
    "\n",
    "\n",
    "Now, we have an idea about where the best $K$ lies, but some of the values we didn't try could result in a  better performance.\n",
    "\n",
    "* Re-run a GridSearch trying some values for $K$ around to your previous best value\n",
    "* What are the `best_score` and `best_k` for this refined GridSearch?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model\n",
    "\n",
    "model2 = KNeighborsRegressor()\n",
    "# Hyperparameter Grid\n",
    "grid2 = {'n_neighbors':list(range(1,51))}\n",
    "\n",
    "# Instantiate Grid Search\n",
    "g_search2 = GridSearchCV(model2,grid2,cv = 5, n_jobs=-1)\n",
    "\n",
    "# Fit data to Grid Search\n",
    "g_search2.fit(X_train, y_train);\n",
    "best_score = round(g_search2.best_score_,2)\n",
    "\n",
    "#g_search2.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***üß™ Test your code***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.10.6, pytest-7.1.3, pluggy-1.0.0 -- /home/ladyhamster/.pyenv/versions/3.10.6/envs/lewagon/bin/python\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/ladyhamster/code/lady-hamster/05-ML/05-Model-Tuning/data-workflow/tests\n",
      "plugins: anyio-3.6.2, asyncio-0.19.0\n",
      "asyncio: mode=strict\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 2 items\n",
      "\n",
      "test_knn.py::TestKnn::test_best_k \u001b[32mPASSED\u001b[0m\u001b[32m                                 [ 50%]\u001b[0m\n",
      "test_knn.py::TestKnn::test_best_score \u001b[32mPASSED\u001b[0m\u001b[32m                             [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m2 passed\u001b[0m\u001b[32m in 0.22s\u001b[0m\u001b[32m ===============================\u001b[0m\n",
      "\n",
      "\n",
      "üíØ You can commit your code:\n",
      "\n",
      "\u001b[1;32mgit\u001b[39m add tests/knn.pickle\n",
      "\n",
      "\u001b[32mgit\u001b[39m commit -m \u001b[33m'Completed knn step'\u001b[39m\n",
      "\n",
      "\u001b[32mgit\u001b[39m push origin master\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nbresult import ChallengeResult\n",
    "result = ChallengeResult('knn',\n",
    "                         best_k=best_k,\n",
    "                         best_score=best_score)\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Visual check (manual GridSearch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚òùÔ∏è This problem is actually simple enough to perform a GridSearch manually.\n",
    "\n",
    "‚ùì **Question(Manual GridSearch)** ‚ùì\n",
    "\n",
    "- Loop manually over all values of $K$ from $1$ to $50$ and store the average of the cross-validated scores of each model in a list.\n",
    "- Plot the scores as a function of $K$ to visually find the best $K$ using the `Elbow Method`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "test_ks = []\n",
    "scores = []\n",
    "\n",
    "for k in range(1,51):\n",
    "    model3 = KNeighborsRegressor(n_neighbors=k)\n",
    "    check3 = cross_validate(model3, X_train, y_train, cv=5)\n",
    "    scores.append(check3['test_score'].mean())\n",
    "    test_ks.append(k)\n",
    "\n",
    "plt.plot(test_ks,scores)\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùìCan you guess what makes GridSearchCV a better option than such manual loop ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Answer</summary>\n",
    "\n",
    "- Sklearn's `n_jobs=-1` allows you to parallelize the search, utilizing all of your CPU cores\n",
    "- What if you had multiple hyper-parameters to co-optimize?\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. GridSearch with multiple parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üë©üèª‚Äçüè´ KNNRegressor suppports various _distance metrics_ via the hyper-parameter `p` \n",
    "\n",
    "üìö [sklearn.neighbors.KNeighborsRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html)\n",
    "\n",
    "‚ùì **Question (tuning multiple parameters)** ‚ùì\n",
    "\n",
    "\n",
    "* Use GridSearchCV to search for the best $K$ and $p$ simultaneously.\n",
    "    * Try all combinations for $K = [1, 5, 10, 20, 50]$ and $p = [1, 2, 3]$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# Instantiate model\n",
    "\n",
    "model3 = KNeighborsRegressor()\n",
    "# Hyperparameter Grid\n",
    "grid3 = {'n_neighbors':[1,5,10,20,50],'p':[1,2,3]}\n",
    "\n",
    "# Instantiate Grid Search\n",
    "g_search3 = GridSearchCV(model3,grid3,cv = 5, n_jobs=-1)\n",
    "\n",
    "# Fit data to Grid Search\n",
    "g_search3.fit(X_train, y_train);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question (number of submodels)**‚ùì\n",
    "\n",
    "How many submodels did you train overall?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Hint</summary>\n",
    "\n",
    "Much more than 15. Think twice :)\n",
    "    <details>\n",
    "    <summary>Answer</summary>\n",
    "\n",
    "75 models due to CV=5\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submodels = 15*5\n",
    "submodels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question (best parameters and best score after tuning the model with multiple parameters)**‚ùì\n",
    "\n",
    "What are the *best parameters* and the *best score*?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = g_search3.best_params_\n",
    "best_score = round(g_search3.best_score_,2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Random Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see whether a RandomizedSearch can find a better combination with the same number of models being fitted.\n",
    "\n",
    "‚ùì **Question (RandomizedSearchCV)** ‚ùì\n",
    "\n",
    "Use `RandomizedSearchCV` to\n",
    "- Randomly sample $K$ from a uniform `scipy.stats.randint(1,50)` ([doc](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.randint.html)) distribution\n",
    "- Sample $p$ from a list $[1,2,3]$\n",
    "- Use the correct numbers of `n_iter` and `cv` to fit the exact same numbers of models as in your previous GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7969255879201194"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy import stats\n",
    "\n",
    "model4 = KNeighborsRegressor()\n",
    "grid4 = {'n_neighbors':stats.randint(1,50),'p':[1,2,3]}\n",
    "\n",
    "r_search = RandomizedSearchCV(model4,grid4,n_iter=75,n_jobs=-1,cv=5)\n",
    "r_search.fit(X_train,y_train)\n",
    "r_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Generalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question (finetuning your model one more time)**‚ùì\n",
    "\n",
    "- Refine your RandomsearchCV if you want\n",
    "- Choose your best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "best_model = r_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try to display your `cv_results` as a `DataFrame`, this will help you visualize what's going on inside the CV! üòâ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_neighbors</th>\n",
       "      <th>param_p</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001611</td>\n",
       "      <td>0.000304</td>\n",
       "      <td>0.003362</td>\n",
       "      <td>0.000322</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>{'n_neighbors': 17, 'p': 2}</td>\n",
       "      <td>0.731574</td>\n",
       "      <td>0.812517</td>\n",
       "      <td>0.720811</td>\n",
       "      <td>0.826772</td>\n",
       "      <td>0.725451</td>\n",
       "      <td>0.763425</td>\n",
       "      <td>0.046250</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001307</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>0.102195</td>\n",
       "      <td>0.005254</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>{'n_neighbors': 9, 'p': 3}</td>\n",
       "      <td>0.701139</td>\n",
       "      <td>0.784972</td>\n",
       "      <td>0.665880</td>\n",
       "      <td>0.805951</td>\n",
       "      <td>0.690930</td>\n",
       "      <td>0.729774</td>\n",
       "      <td>0.055247</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000978</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.107998</td>\n",
       "      <td>0.001815</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>{'n_neighbors': 6, 'p': 3}</td>\n",
       "      <td>0.675765</td>\n",
       "      <td>0.754340</td>\n",
       "      <td>0.667509</td>\n",
       "      <td>0.844996</td>\n",
       "      <td>0.669192</td>\n",
       "      <td>0.722360</td>\n",
       "      <td>0.069382</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001320</td>\n",
       "      <td>0.000331</td>\n",
       "      <td>0.003610</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>{'n_neighbors': 26, 'p': 2}</td>\n",
       "      <td>0.738524</td>\n",
       "      <td>0.811411</td>\n",
       "      <td>0.699374</td>\n",
       "      <td>0.800078</td>\n",
       "      <td>0.733302</td>\n",
       "      <td>0.756538</td>\n",
       "      <td>0.042518</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001104</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>0.009362</td>\n",
       "      <td>0.000665</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 41, 'p': 1}</td>\n",
       "      <td>0.753112</td>\n",
       "      <td>0.797950</td>\n",
       "      <td>0.715240</td>\n",
       "      <td>0.789323</td>\n",
       "      <td>0.722191</td>\n",
       "      <td>0.755564</td>\n",
       "      <td>0.033711</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.001611      0.000304         0.003362        0.000322   \n",
       "1       0.001307      0.000233         0.102195        0.005254   \n",
       "2       0.000978      0.000038         0.107998        0.001815   \n",
       "3       0.001320      0.000331         0.003610        0.000335   \n",
       "4       0.001104      0.000165         0.009362        0.000665   \n",
       "\n",
       "  param_n_neighbors param_p                       params  split0_test_score  \\\n",
       "0                17       2  {'n_neighbors': 17, 'p': 2}           0.731574   \n",
       "1                 9       3   {'n_neighbors': 9, 'p': 3}           0.701139   \n",
       "2                 6       3   {'n_neighbors': 6, 'p': 3}           0.675765   \n",
       "3                26       2  {'n_neighbors': 26, 'p': 2}           0.738524   \n",
       "4                41       1  {'n_neighbors': 41, 'p': 1}           0.753112   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.812517           0.720811           0.826772           0.725451   \n",
       "1           0.784972           0.665880           0.805951           0.690930   \n",
       "2           0.754340           0.667509           0.844996           0.669192   \n",
       "3           0.811411           0.699374           0.800078           0.733302   \n",
       "4           0.797950           0.715240           0.789323           0.722191   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.763425        0.046250               20  \n",
       "1         0.729774        0.055247               56  \n",
       "2         0.722360        0.069382               61  \n",
       "3         0.756538        0.042518               28  \n",
       "4         0.755564        0.033711               32  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_df = pd.DataFrame(r_search.cv_results_)\n",
    "best_model_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question (Evaluation of the \"best\" model)** ‚ùì\n",
    "\n",
    "* Time has come to discover our model's performance with \"best params\" on the **unseen** test set `X_test`.\n",
    "    * Compute the r2 score for the test set and save it as `r2_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7731141456725311"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_test = best_model.score(X_test,y_test)\n",
    "r2_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question (Taking a step back)** ‚ùì\n",
    "\n",
    "Would you consider the optimized model to generalize well?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Answer</summary>\n",
    "\n",
    "Test score may decrease a bit with train set. Probably not more than 5%. This can be due to\n",
    "- A non-representative train/test split\n",
    "- A cross-val number too small leading to overfitting the model-tuning phase. The more you cross-validated, the more robust your findings will generalize - but you can't increase cv too much if your dataset is too small as you won't keep enough observations in each fold to be representative.\n",
    "- Our dataset is very small and our hyperparameter optimization is thus extremely dependent (and overfitting) on our train/test split. Always make sure your dataset is much bigger than the total number of hyperparameter combinations you are trying out!\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***üß™ Test your code***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.10.6, pytest-7.1.3, pluggy-1.0.0 -- /home/ladyhamster/.pyenv/versions/3.10.6/envs/lewagon/bin/python\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/ladyhamster/code/lady-hamster/05-ML/05-Model-Tuning/data-workflow/tests\n",
      "plugins: anyio-3.6.2, asyncio-0.19.0\n",
      "asyncio: mode=strict\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 1 item\n",
      "\n",
      "test_r2.py::TestR2::test_r2 \u001b[32mPASSED\u001b[0m\u001b[32m                                       [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 0.16s\u001b[0m\u001b[32m ===============================\u001b[0m\n",
      "\n",
      "\n",
      "üíØ You can commit your code:\n",
      "\n",
      "\u001b[1;32mgit\u001b[39m add tests/r2.pickle\n",
      "\n",
      "\u001b[32mgit\u001b[39m commit -m \u001b[33m'Completed r2 step'\u001b[39m\n",
      "\n",
      "\u001b[32mgit\u001b[39m push origin master\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nbresult import ChallengeResult\n",
    "result = ChallengeResult('r2', \n",
    "                         r2_test=r2_test)\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üèÅ Congratulations! Now, you know how to finetune a model using either a GridSearchCV or a RandomizedSearchCV \n",
    "\n",
    "üíæ Don't forget to¬†`git add/commit/push`¬†your notebook...\n",
    "\n",
    "üöÄ ... and move on to the next challenge!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
